{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7kkQEObQ0V3"
      },
      "source": [
        "# Assignment 1  \n",
        "\n",
        "For the exercises below you can use the numpy and scipy libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0ghMniWQ0V8"
      },
      "source": [
        "## Problem 1: Simulation (20 points)\n",
        "\n",
        "Review any of the probability theory links [provided in your course site](https://pantelis.github.io/artificial-intelligence/aiml-common/lectures/ml-math/probability/index.html). The exercise refers to Example 6.6 of the  [Math for ML book](https://mml-book.github.io/book/mml-book.pdf).\n",
        "\n",
        "### Problem 1A (15 points)\n",
        "\n",
        "Simulate (sample from) the bivariate normal distribution with the shown parameters obtaining a plot similar to Figure 6.8b that shows the simulation result from a different bivariate Gaussian distribution.  You can generate $m=200$ samples/points (10 points)\n",
        "\n",
        "### Problem 1B (5 points)\n",
        "\n",
        "Plot the contours of the bivariate Gaussian distribution and the simulated points in the same plot. (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY8if4oQQ0V-"
      },
      "outputs": [],
      "source": [
        "# Insert your answer here and fee free to add markdown cells as needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeNMaFYXQ0WA"
      },
      "source": [
        "## Problem 2: Projection (20 points)\n",
        "\n",
        "You may want to review these [linear algebra](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab) videos or the [other linear algebra links](https://pantelis.github.io/artificial-intelligence/aiml-common/lectures/ml-math/linear-algebra/index.html) provided in your course site.\n",
        "\n",
        "Simulate a 3-dimensional (3d) Gaussian random vector with the following covariance matrix.\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "4 & 2 & 1 \\\\\n",
        "2 & 3 & 1.5 \\\\\n",
        "1 & 1.5 & 2 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Using the Singular Value Decomposition (SVD) compute the projection of the simulated vectors onto the subspace spanned by the first two principal components.\n",
        "\n",
        "### Problem 2A (5 points)\n",
        "\n",
        "What determines the principal components ?\n",
        "\n",
        "### Problem 2B (5 points)\n",
        "\n",
        "What determines the positive or negative correlations between the components ?\n",
        "\n",
        "### Problem 2C (10 points)\n",
        "\n",
        "Plot the projected vectors and show whether or not the projection agrees with the positive or negative correlations of the original matrix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpurAY7EQ0WB"
      },
      "outputs": [],
      "source": [
        "# Insert your answer here and fee free to add markdown cells as needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKvTyeeiQ0WC"
      },
      "source": [
        "### Problem 3: Stochastic Gradient Descent (30 points)\n",
        "\n",
        "In class we covered the baseline stochastic gradient descent.  Using the linear regression example from the class notes, develop from scratch the baseline SGD algorithm. :\n",
        "\n",
        "Clearly state the hyperparameters you used and present the loss vs epoch plot that demonstrates the convergence of the algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gkMBZLHQ0WD"
      },
      "outputs": [],
      "source": [
        "# Insert your answer here and fee free to add markdown cells as needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe4bl6kQQ0WD"
      },
      "source": [
        "### Problem 4: SGD Enhancements (30 points)\n",
        "\n",
        "In this exercise you will implement some enhancements for the linear regression problem from scratch that can improve the convergence speed of the algorithm.\n",
        "\n",
        "1. Momentum (15 points)\n",
        "2. Adam (15 points)\n",
        "\n",
        "Clearly state the hyperparameters you used and present the loss vs epoch plot that demonstrates the convergence of each algorithm and compared to the baseline SGD algorithm. You can include all plots in the same figure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTt5md5LQ0WE"
      },
      "outputs": [],
      "source": [
        "# Insert your answer here and fee free to add markdown cells as needed"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
